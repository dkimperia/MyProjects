Дано краткое описание параллельного алгоритма моделирования многослойного персептрона и параллельного алгоритма обучения iRprop. Алгоритмы используют параллельные вычисления с разделяемой памятью и параллельность на уровне инструкций процессора. Приведено сравнение быстродействия последовательного и параллельного алгоритмов, а также динамика изменения их быстродействия за последние 6 лет. Ключевые слова: многослойный персептрон, обучение многослойного персептрона, параллельные вычисления с разделяемой памятью, SIMD инструкции.

Введение

Алгоритмы моделирования и обучения нейронных сетей имеют высокую вычислительную сложность. Во многих приложениях ИНС, вычислительная сложность пропорциональна квадрату количества настраиваемых связей ИНС. Обучение больших ИНС может занимать несколько дней. Ускорение процесса их обучения поможет исследователям быстрее находить оптимальные топологии и добиваться более точных результатов прогнозирования и распознавания. Также быстродействие моделей ИНС очень важно для систем принятия решений в реальном времени, например систем, использующих машинное зрение.

Объем задач, решаемых с помощью ИНС, непрерывно растет. Увеличивается сложность моделей, ужесточаются бизнес-требования, предъявляемые к моделям. Все это приводит к увеличению вычислительной сложности.

Ранее созданные программы не могут использовать даже половину вычислительной мощности современных процессоров, так как не используют параллельные вычисления, а потенциал увеличения производительности отдельно взятого процессорного ядра практически исчерпан. Быстродействие ранее созданных алгоритмов на современных компьютерах будет повышаться медленнее роста сложности задач, что приведет к неэффективности систем, использующих эти алгоритмы. Поэтому сейчас очень важно создавать новые, параллельные реализации моделей ИНС, чтобы они могли использовать возрастающую вычислительную мощь современных ЭВМ и легко масштабировались для решения больших и сложных практических задач.

Проблема разработки параллельных алгоритмов встала относительно недавно, но ее актуальность непрерывно растет. На данный момент имеется совсем немного теоретических разработок и методов организации параллельных вычислений. Поэтому необходимо искать новые способы распараллеливания алгоритмов, разрабатывать методы выделения шагов, способных выполняться параллельно.

Использование параллельных вычислений позволит повысить энергоэффективность процесса моделирования и обучения, измеренную в миллионах операций с плавающей точкой (mflops) на затраченный ватт электроэнергии.

1. Постановка задачи

Для популярных в настоящее время математических моделей ИНС и моделей их обучения необходимо разработать параллельные алгоритмы, позволяющие в полной мере использовать вычислительную мощь современных многоядерных процессоров. Параллельные алгоритмы должны хорошо масштабироваться. Это означает, что со временем количество вычислительных потоков, способных выполняться одновременно, будет расти, и алгоритмы должны быть построены таким образом, чтобы обеспечить работой как можно большее количество параллельных потоков.

2. Выбор метода исследования

Быстродействие реализации сравнивается с быстродействием алгоритмов, реализованных в библиотеке Fast Artificial Neural Network Library (FANN) версии 1.2.0 [1]. Реализация ИНС из библиотеки FANN обладает отличным быстродействием и использует оптимизации, такие как оптимизация доступа к данным, разворачивание циклов (loop unrolling).

Быстродействие измерялось в секундах, затраченных реализациями алгоритмов на выполнение одних и тех же вычислений. Высчитывалось среднее время из десяти проходов для каждой реализации.

В ходе тестирования было установлено, что реализации многослойного персептрона и iRprop [2] не требовательны к пропускной способности памяти. Их быстродействие ограничено только быстродействием процессора. Было проведено тестирование реализации на различных процессорах Intel от 2004 до 2009 года выпуска, от Pentium 4 до Core i7, что позволит сделать некоторые выводы относительно масштабируемости реализаций и спрогнозировать будущие изменения быстродействия.

3. Описание параллельных алгоритмов

3.1. Параллельная реализация многослойного персептрона

Многослойный персептрон реализован в виде класса Perceptron. Этот класс отвечает за прямое распространение сигнала в нейронной сети и информацию о топологии сети.

Perceptron содержит данные двух видов: данные для чтения (Structure) и данные для чтения и записи (Data). Во время функционирования нейронной сети ее структура не меняется, т.е. описание структуры сети используется только для чтения, в то время как Data полностью перезаписывается при прямом распространении сигнала в сети. Чтобы можно было выполнять прямое распространение сигнала параллельно, необходимо создать копию экземпляра Perceptron для каждого потока, но так как структура персептрона при этом не меняется, ее можно не копировать. Для этих целей был создан метод Perceptron::ParallelCopy. Таким образом, объект Structure может использоваться несколькими объектами Perceptron. Для разделяемых объектов Structure реализован подсчет ссылок, это позволяет удалить класс Structure, если на него не ссылается ни один из Perceptron.

При прямом распространении сигнала выходной сигнал для каждого нейрона слоя рассчитывается параллельно. Это реализовано с помощью стандарта OpenMP [3].

Число синапсов каждого нейрона сети сделано кратным четырем. Например, если число синапсов нейрона - 13, оно будет увеличено до 16. Однако пользователь по-прежнему может работать только с 13 синапсами, веса добавленных 3 синапсов всегда равны нулю. Добавление дополнительных синапсов делается для того, чтобы можно было применить векторные инструкции для SSE (Streaming SIMD Extension) [4, 5] для вычисления взвешенной суммы входов нейронов. Инструкции SSE позволяют выполнить одну и ту же арифметическую операцию над 4 вещественными числами одинарной точности одной командой. Использование SSE позволило увеличить быстродействие сети в 2,5 раза.

3.2. Параллельная реализация алгоритма iRprop

При обучении ИНС с помощью алгоритма iRprop ей сначала предъявляются все примеры обучающей выборки, для каждого примера вычисляется ошибка аппроксимации (разность между выходом нейронной сети и полученным значением). Происходит обратное распространение ошибки, т.е. распространение сигнала от выхода нейронной сети ко

dE

входу. Вычисляется оценка частной производной -, где E(W) - функция ошибки

нейронной сети от всех весов сети W; wj - вес нейронной сети, связывающий i нейрон с j, wij е W .

Эти шаги можно выполнить параллельно. Для этого каждый вычислительный поток должен иметь параллельную копию многослойного персептрона (можно использовать Per-ceptron::CloneParallel), копию массива отклонений (ошибок) каждого нейрона в сети и копию массива оценок частной производной функции ошибки по весу для каждого настраиваемого веса в сети.

4. Постановка эксперимента

В результате выполнения данной работы была написана библиотека классов, содержащая параллельную реализацию многослойного персептрона и параллельную реализацию алгоритма обучения iRprop.

Было произведено тестирование библиотеки. Для этого была взята большая нейронная сеть с 200 входами, 100 нейронами в скрытом слое, 1 нейроном в выходном слое. Сеть представляла собой многослойный персептрон, в котором каждый нейрон последующего слоя был связан со всеми нейронами предыдущего слоя. Для сравнения быстродействия использовалась библиотека FANN [1]. Для компиляции параллельной и последовательной (FANN) реализаций использовался компилятор Microsoft C++ Compiler 10.

Веса нейронной сети инициализировались каждый раз одними и теми же значениями, одинаковыми для FANN сети и для описываемой реализации. Далее на каждой тестовой машине проводились 100 эпох обучения нейронной сети и измерялось среднее время для 10 попыток обучения. Это позволило сразу задействовать алгоритмы прямого распространения сигнала в нейронной сети и алгоритм iRprop, сравнивать разные реализации алго-

i
Не можете найти то, что вам нужно? Попробуйте сервис подбора литературы.
ритмов в одинаковых условиях и увеличить точность оценок за счет повторения экспериментов.

Были проведены тесты параллельной реализации с различным количеством вычислительных потоков. На каждой системе были проведены тесты с использованием одного вычислительного потока (то же самое, что использовать последовательные вычисления), двух, и т.д. до n, где n - максимальное количество параллельных вычислительных потоков в системе. Например, для процессора Intel Core i7 920 с 4 физическими ядрами, каждое из которых содержит два логических, этот показатель будет равен 2^4 = 8. Была вычислена оценка эффективности параллельных вычислений. Эффективность распараллеливания показывает, какой процент времени вычислительные потоки тратят на эффективную работу, на вычисления. Значение 60% означает, что вычислительные потоки 60% времени выполняют полезную работу и 40% времени простаивают или тратят на синхронизацию. Эффективность вычислялась по формуле

5= Гпос • 100%, (1)

n•^пар

где Tпос - время, затраченное на последовательное вычисление; Tпар - время, затраченное на параллельное вычисление; n - количество вычислительных потоков.